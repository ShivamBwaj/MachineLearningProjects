{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:32:54.097138Z","iopub.execute_input":"2026-02-19T11:32:54.097322Z","iopub.status.idle":"2026-02-19T11:33:02.954133Z","shell.execute_reply.started":"2026-02-19T11:32:54.097303Z","shell.execute_reply":"2026-02-19T11:33:02.953574Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:33:02.955602Z","iopub.execute_input":"2026-02-19T11:33:02.956067Z","iopub.status.idle":"2026-02-19T11:33:03.214684Z","shell.execute_reply.started":"2026-02-19T11:33:02.956038Z","shell.execute_reply":"2026-02-19T11:33:03.213647Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),   # for ResNet50\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:33:03.218001Z","iopub.execute_input":"2026-02-19T11:33:03.218386Z","iopub.status.idle":"2026-02-19T11:33:03.262945Z","shell.execute_reply.started":"2026-02-19T11:33:03.218355Z","shell.execute_reply":"2026-02-19T11:33:03.262123Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(\"/kaggle/input/brain-tumor-mri-dataset/Training\", transform=transform)\ntest_dataset  = datasets.ImageFolder(\"/kaggle/input/brain-tumor-mri-dataset/Testing\", transform=transform)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=32,\n    shuffle=True,\n    num_workers=4,      \n    pin_memory=True\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=32,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\nnum_classes = 4\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:37:22.733127Z","iopub.execute_input":"2026-02-19T11:37:22.733786Z","iopub.status.idle":"2026-02-19T11:37:25.108034Z","shell.execute_reply.started":"2026-02-19T11:37:22.733756Z","shell.execute_reply":"2026-02-19T11:37:25.107489Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# normal resnet 50","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n\n# Freeze backbone (for first experiment)\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Replace final layer\nmodel.fc = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(model.fc.in_features, num_classes)\n)\n\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:37:32.764845Z","iopub.execute_input":"2026-02-19T11:37:32.765578Z","iopub.status.idle":"2026-02-19T11:37:33.163300Z","shell.execute_reply.started":"2026-02-19T11:37:32.765550Z","shell.execute_reply":"2026-02-19T11:37:33.162744Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.fc.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:37:33.954788Z","iopub.execute_input":"2026-02-19T11:37:33.955359Z","iopub.status.idle":"2026-02-19T11:37:33.958965Z","shell.execute_reply.started":"2026-02-19T11:37:33.955332Z","shell.execute_reply":"2026-02-19T11:37:33.958459Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"epochs = 10\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print(f\"Epoch [{epoch+1}/{epochs}] \"\n          f\"Loss: {running_loss/len(train_loader):.4f} \"\n          f\"Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:37:38.471244Z","iopub.execute_input":"2026-02-19T11:37:38.471796Z","iopub.status.idle":"2026-02-19T11:40:41.106881Z","shell.execute_reply.started":"2026-02-19T11:37:38.471766Z","shell.execute_reply":"2026-02-19T11:40:41.105977Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] Loss: 0.6543 Accuracy: 75.73%\nEpoch [2/10] Loss: 0.4564 Accuracy: 82.91%\nEpoch [3/10] Loss: 0.4231 Accuracy: 84.18%\nEpoch [4/10] Loss: 0.3786 Accuracy: 85.98%\nEpoch [5/10] Loss: 0.3976 Accuracy: 84.91%\nEpoch [6/10] Loss: 0.3804 Accuracy: 85.59%\nEpoch [7/10] Loss: 0.3754 Accuracy: 85.80%\nEpoch [8/10] Loss: 0.3887 Accuracy: 85.61%\nEpoch [9/10] Loss: 0.3721 Accuracy: 86.12%\nEpoch [10/10] Loss: 0.3684 Accuracy: 86.29%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Test Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:41:38.273076Z","iopub.execute_input":"2026-02-19T11:41:38.273639Z","iopub.status.idle":"2026-02-19T11:41:44.430079Z","shell.execute_reply.started":"2026-02-19T11:41:38.273603Z","shell.execute_reply":"2026-02-19T11:41:44.429354Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 77.75%\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# normal Efficient net b4","metadata":{}},{"cell_type":"code","source":"transform_b4 = transforms.Compose([\n    transforms.Resize((380, 380)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:41:49.173133Z","iopub.execute_input":"2026-02-19T11:41:49.173453Z","iopub.status.idle":"2026-02-19T11:41:49.178097Z","shell.execute_reply.started":"2026-02-19T11:41:49.173411Z","shell.execute_reply":"2026-02-19T11:41:49.177310Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"model = models.efficientnet_b4(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.classifier = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(model.classifier[1].in_features, num_classes)\n)\n\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.classifier.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:41:49.425149Z","iopub.execute_input":"2026-02-19T11:41:49.425578Z","iopub.status.idle":"2026-02-19T11:41:50.017997Z","shell.execute_reply.started":"2026-02-19T11:41:49.425544Z","shell.execute_reply":"2026-02-19T11:41:50.017469Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"epochs = 10\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print(f\"Epoch [{epoch+1}/{epochs}] \"\n          f\"Loss: {running_loss/len(train_loader):.4f} \"\n          f\"Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:41:52.774038Z","iopub.execute_input":"2026-02-19T11:41:52.774598Z","iopub.status.idle":"2026-02-19T11:45:32.524599Z","shell.execute_reply.started":"2026-02-19T11:41:52.774570Z","shell.execute_reply":"2026-02-19T11:45:32.523816Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] Loss: 0.8876 Accuracy: 72.54%\nEpoch [2/10] Loss: 0.5910 Accuracy: 80.43%\nEpoch [3/10] Loss: 0.5142 Accuracy: 82.45%\nEpoch [4/10] Loss: 0.4755 Accuracy: 83.68%\nEpoch [5/10] Loss: 0.4505 Accuracy: 83.89%\nEpoch [6/10] Loss: 0.4293 Accuracy: 84.98%\nEpoch [7/10] Loss: 0.4199 Accuracy: 84.27%\nEpoch [8/10] Loss: 0.4194 Accuracy: 84.46%\nEpoch [9/10] Loss: 0.4076 Accuracy: 85.09%\nEpoch [10/10] Loss: 0.4068 Accuracy: 85.02%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Test Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:45:32.526165Z","iopub.execute_input":"2026-02-19T11:45:32.526407Z","iopub.status.idle":"2026-02-19T11:45:38.676102Z","shell.execute_reply.started":"2026-02-19T11:45:32.526383Z","shell.execute_reply":"2026-02-19T11:45:38.675413Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 81.19%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Fine tune Res net 50","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(model.fc.in_features, 4)\n)\nfor param in model.layer4.parameters():\n    param.requires_grad = True\n\nfor param in model.fc.parameters():\n    param.requires_grad = True\n    model = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:46:23.609078Z","iopub.execute_input":"2026-02-19T11:46:23.609388Z","iopub.status.idle":"2026-02-19T11:46:24.072041Z","shell.execute_reply.started":"2026-02-19T11:46:23.609358Z","shell.execute_reply":"2026-02-19T11:46:24.071482Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=1e-4   # ðŸ”¥ lower than before\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:46:25.609401Z","iopub.execute_input":"2026-02-19T11:46:25.609758Z","iopub.status.idle":"2026-02-19T11:46:25.614505Z","shell.execute_reply.started":"2026-02-19T11:46:25.609730Z","shell.execute_reply":"2026-02-19T11:46:25.613723Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"epochs = 10\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print(f\"Epoch [{epoch+1}/{epochs}] \"\n          f\"Loss: {running_loss/len(train_loader):.4f} \"\n          f\"Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:46:26.119620Z","iopub.execute_input":"2026-02-19T11:46:26.119917Z","iopub.status.idle":"2026-02-19T11:50:48.300239Z","shell.execute_reply.started":"2026-02-19T11:46:26.119893Z","shell.execute_reply":"2026-02-19T11:50:48.299509Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] Loss: 0.2712 Accuracy: 90.25%\nEpoch [2/10] Loss: 0.0592 Accuracy: 98.09%\nEpoch [3/10] Loss: 0.0306 Accuracy: 98.98%\nEpoch [4/10] Loss: 0.0170 Accuracy: 99.46%\nEpoch [5/10] Loss: 0.0183 Accuracy: 99.50%\nEpoch [6/10] Loss: 0.0174 Accuracy: 99.52%\nEpoch [7/10] Loss: 0.0127 Accuracy: 99.61%\nEpoch [8/10] Loss: 0.0094 Accuracy: 99.71%\nEpoch [9/10] Loss: 0.0160 Accuracy: 99.54%\nEpoch [10/10] Loss: 0.0104 Accuracy: 99.73%\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Test Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:50:48.301868Z","iopub.execute_input":"2026-02-19T11:50:48.302131Z","iopub.status.idle":"2026-02-19T11:50:53.875593Z","shell.execute_reply.started":"2026-02-19T11:50:48.302106Z","shell.execute_reply":"2026-02-19T11:50:53.874822Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 94.75%\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Fine tune Efficient net b4\n","metadata":{}},{"cell_type":"code","source":"model = models.efficientnet_b4(pretrained=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:52:22.810610Z","iopub.execute_input":"2026-02-19T11:52:22.811157Z","iopub.status.idle":"2026-02-19T11:52:23.189078Z","shell.execute_reply.started":"2026-02-19T11:52:22.811126Z","shell.execute_reply":"2026-02-19T11:52:23.188437Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:52:23.215870Z","iopub.execute_input":"2026-02-19T11:52:23.216109Z","iopub.status.idle":"2026-02-19T11:52:23.221240Z","shell.execute_reply.started":"2026-02-19T11:52:23.216087Z","shell.execute_reply":"2026-02-19T11:52:23.220472Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"model.classifier = nn.Sequential(\n    nn.Dropout(0.5),\n    nn.Linear(model.classifier[1].in_features, 4)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:52:23.490210Z","iopub.execute_input":"2026-02-19T11:52:23.490518Z","iopub.status.idle":"2026-02-19T11:52:23.495129Z","shell.execute_reply.started":"2026-02-19T11:52:23.490491Z","shell.execute_reply":"2026-02-19T11:52:23.494339Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"for param in model.features[-2:].parameters():\n    param.requires_grad = True\n\nfor param in model.classifier.parameters():\n    param.requires_grad = True\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:52:23.944576Z","iopub.execute_input":"2026-02-19T11:52:23.945042Z","iopub.status.idle":"2026-02-19T11:52:23.989452Z","shell.execute_reply.started":"2026-02-19T11:52:23.945017Z","shell.execute_reply":"2026-02-19T11:52:23.988758Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=1e-4\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:52:27.336949Z","iopub.execute_input":"2026-02-19T11:52:27.337642Z","iopub.status.idle":"2026-02-19T11:52:27.343372Z","shell.execute_reply.started":"2026-02-19T11:52:27.337611Z","shell.execute_reply":"2026-02-19T11:52:27.342852Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"epochs = 10\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print(f\"Epoch [{epoch+1}/{epochs}] \"\n          f\"Loss: {running_loss/len(train_loader):.4f} \"\n          f\"Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T11:52:27.903763Z","iopub.execute_input":"2026-02-19T11:52:27.904448Z","iopub.status.idle":"2026-02-19T11:57:00.177306Z","shell.execute_reply.started":"2026-02-19T11:52:27.904404Z","shell.execute_reply":"2026-02-19T11:57:00.176315Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/10] Loss: 1.0255 Accuracy: 63.82%\nEpoch [2/10] Loss: 0.4944 Accuracy: 81.50%\nEpoch [3/10] Loss: 0.3826 Accuracy: 85.55%\nEpoch [4/10] Loss: 0.3297 Accuracy: 87.57%\nEpoch [6/10] Loss: 0.2601 Accuracy: 90.27%\nEpoch [7/10] Loss: 0.2339 Accuracy: 91.55%\nEpoch [8/10] Loss: 0.2170 Accuracy: 91.77%\nEpoch [9/10] Loss: 0.1986 Accuracy: 92.14%\nEpoch [10/10] Loss: 0.1810 Accuracy: 93.34%\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Test Accuracy: {100*correct/total:.2f}%\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# With Scheduling Resnet 50 fine tuned","metadata":{}},{"cell_type":"code","source":"\ntransform_resnet = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\n\ntransform_effnet = transforms.Compose([\n    transforms.Resize((380, 380)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_resnet():\n\n    train_dataset = datasets.ImageFolder(\"Training\", transform=transform_resnet)\n    val_dataset   = datasets.ImageFolder(\"Testing\", transform=transform_resnet)\n\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\n\n    model = models.resnet50(pretrained=True)\n\n    # Freeze everything\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Replace classifier\n    model.fc = nn.Sequential(\n        nn.Dropout(0.5),\n        nn.Linear(model.fc.in_features, 4)\n    )\n\n    # Unfreeze last block\n    for param in model.layer4.parameters():\n        param.requires_grad = True\n\n    for param in model.fc.parameters():\n        param.requires_grad = True\n\n    model = model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    optimizer = optim.Adam(\n        filter(lambda p: p.requires_grad, model.parameters()),\n        lr=1e-4\n    )\n\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        mode='min',\n        factor=0.1,\n        patience=2,\n        verbose=True\n    )\n\n    best_acc = 0\n    epochs = 12\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        val_acc = 100 * correct / total\n\n        scheduler.step(val_loss)\n\n        print(f\"Epoch [{epoch+1}/{epochs}] \"\n              f\"TrainLoss: {train_loss/len(train_loader):.4f} \"\n              f\"ValLoss: {val_loss/len(val_loader):.4f} \"\n              f\"ValAcc: {val_acc:.2f}%\")\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            torch.save(model.state_dict(), \"best_resnet50.pth\")\n\n    print(\"Best Val Accuracy:\", best_acc)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# efficient net with scheduler","metadata":{}},{"cell_type":"code","source":"def train_efficientnet():\n\n    train_dataset = datasets.ImageFolder(\"Training\", transform=transform_effnet)\n    val_dataset   = datasets.ImageFolder(\"Testing\", transform=transform_effnet)\n\n    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n    val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n\n    model = models.efficientnet_b4(pretrained=True)\n\n    # Freeze all\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Replace classifier\n    model.classifier = nn.Sequential(\n        nn.Dropout(0.5),\n        nn.Linear(model.classifier[1].in_features, 4)\n    )\n\n    # Unfreeze last 2 feature blocks\n    for param in model.features[-2:].parameters():\n        param.requires_grad = True\n\n    for param in model.classifier.parameters():\n        param.requires_grad = True\n\n    model = model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n\n    optimizer = optim.Adam(\n        filter(lambda p: p.requires_grad, model.parameters()),\n        lr=1e-4\n    )\n\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer,\n        mode='min',\n        factor=0.1,\n        patience=2,\n        verbose=True\n    )\n\n    best_acc = 0\n    epochs = 12\n\n    for epoch in range(epochs):\n        model.train()\n        train_loss = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        val_acc = 100 * correct / total\n\n        scheduler.step(val_loss)\n\n        print(f\"Epoch [{epoch+1}/{epochs}] \"\n              f\"TrainLoss: {train_loss/len(train_loader):.4f} \"\n              f\"ValLoss: {val_loss/len(val_loader):.4f} \"\n              f\"ValAcc: {val_acc:.2f}%\")\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            torch.save(model.state_dict(), \"best_efficientnet_b4.pth\")\n\n    print(\"Best Val Accuracy:\", best_acc)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_resnet()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_efficientnet()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}